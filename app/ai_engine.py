# app/ai_engine.py - VERSI√ìN FINAL DE AJUSTE DE B√öSQUEDA

import os
import google.generativeai as genai
from dotenv import load_dotenv
from app.crud import buscar_productos, obtener_info_empresa

load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    raise ValueError(" Falta la clave API de Google en el archivo .env")

genai.configure(api_key=GOOGLE_API_KEY)

generation_config = {
    "temperature": 0.75,
    "top_p": 0.95,
    "top_k": 40,
    "max_output_tokens": 1024,
}

modelo = genai.GenerativeModel(
    model_name="models/gemini-2.5-flash",
    generation_config=generation_config,
)

def generar_respuesta_con_gemini(contexto: str, pregunta: str, nombre_chatbot: str = "Mocca") -> str:
    """Respuesta r√°pida, con personalidad y sin sobrecargar el modelo."""
    prompt = f"""
Eres {nombre_chatbot}, asistente de Stone Creek Coffee. Ayudas a clientes a elegir caf√©s, chocolates y combos de origen peruano.
Eres amable, entusiasta y breve.

Antes de responder:
1. ¬øQu√© quiere el cliente? (info de un producto, un combo, la direcci√≥n)
2. ¬øQu√© productos tenemos que coinciden? (usando el contexto)
3. Responde en 1-3 frases, con emoji si aplica. ‚òïüç´
4. Termina con una pregunta corta para seguir (ej: ¬øTe gustar√≠a pedirlo?, ¬øTe provoca algo m√°s?).

Contexto:
{contexto}

Pregunta del cliente:
{pregunta}

Responde como {nombre_chatbot}:
"""

    try:
        respuesta = modelo.generate_content(prompt)
        
        if not respuesta.candidates or not respuesta.candidates[0].content.parts:
            return "¬°Ay, me qued√© pensando demasiado! ¬øPodr√≠as decirme un poco m√°s sobre lo que buscas? Por ejemplo: ¬øun caf√©, un chocolate o un combo? ¬°Te ayudar√© con gusto!"

        return respuesta.text.strip()

    except Exception as e:
        # Esto te ayudar√° a diagnosticar si hay problemas de API en el servidor
        print(f"Error de Gemini/API: {e}") 
        return "¬°Ups! Me qued√© sin ideas por un momento. ¬øPodr√≠as intentarlo de nuevo? üôè"

CONVERSATION_HISTORY = {}

def procesar_mensaje_usuario(mensaje: str, user_id: str = "default_user") -> str:
    """Decide si buscar en BD o usar IA, y genera una respuesta con personalidad y memoria."""
    
    if user_id not in CONVERSATION_HISTORY:
        CONVERSATION_HISTORY[user_id] = []

    CONVERSATION_HISTORY[user_id].append({"role": "user", "content": mensaje})

    if len(CONVERSATION_HISTORY[user_id]) > 5:
        CONVERSATION_HISTORY[user_id].pop(0)

    # Obtener info general de la empresa
    info = obtener_info_empresa()
    nombre_chatbot = info.get("chatbot_nombre", "Mocca")
    empresa_descripcion = info.get("empresa_descripcion", "")

    historial_texto = "\n".join([
        f"{'Usuario' if msg['role'] == 'user' else 'Mocca'}: {msg['content']}"
        for msg in CONVERSATION_HISTORY[user_id]
    ])

    
    # Lista de nombres espec√≠ficos (cortos y f√°ciles de buscar)
    # Ordenados por longitud (los m√°s largos primero) para evitar coincidencias parciales incorrectas
    nombres_a_buscar = [
        "fuerte amanecer", "piura blanco", "sal de maras", "geisha de altura",
        "Pack degustaci√≥n caf√©", "Pack degustaci√≥n chocolate", "Pack d√∫o",
        "tunkimayo", "chuncho", "aguaymanto", "cremosa", "descafeinado", 
        "chocolate", "caf√©", "combo", "barra", "tableta", "cafe", "chocolates"
    ]
    
    
    # 2. Palabras clave de informaci√≥n
    es_info_empresa = any(palabra in mensaje.lower() for palabra in ["empresa", "misi√≥n", "visi√≥n", "contacto", "tel√©fono", "email", "direcci√≥n", "ubicados"])

    # 3. Identificar si la consulta es sobre productos
    es_productos = any(palabra in mensaje.lower() for palabra in nombres_a_buscar)


    if es_productos:
        
        # --- L√ìGICA DE EXTRACCI√ìN MEJORADA ---
        termino_busqueda = None
        mensaje_lower = mensaje.lower()
        
        # Iterar para encontrar el nombre de producto m√°s espec√≠fico en el mensaje
        for nombre in nombres_a_buscar:
            if nombre in mensaje_lower:
                termino_busqueda = nombre # Encontr√≥ una coincidencia
                break
        
        # Si no encontr√≥ un nombre espec√≠fico, usa la √∫ltima palabra como √∫ltimo recurso
        if not termino_busqueda:
             termino_busqueda = mensaje_lower.split()[-1]


        # Realiza la b√∫squeda en SQLite
        productos = buscar_productos(termino_busqueda)
        
        # --- L√≥gica de Contexto ---
        if productos:
            # Si encuentra productos, construye el contexto con la informaci√≥n real de la BD
            contexto = "Productos que coinciden con tu b√∫squeda:\n"
            for p in productos:
                # ¬°Asegurar el formato de precio!
                contexto += f"- **{p['nombre']}** (S/ {p['precio']:.2f})\n  {p['descripcion']}\n  Detalles: {p['detalles']}\n\n"
        else:
            # Si la b√∫squeda falla
            contexto = f"""
No encontr√© el producto {termino_busqueda.capitalize()} en el inventario. 
Nuestras categor√≠as principales son: Caf√©s, Chocolates y Combos. 
¬øTe gustar√≠a saber sobre el caf√© Tunkimayo, la Tableta Piura Blanco, o alg√∫n Combo?
"""
        
        # A√±adir historial al contexto
        contexto += f"\n\nHistorial de la conversaci√≥n:\n{historial_texto}"

        respuesta = generar_respuesta_con_gemini(contexto, mensaje, nombre_chatbot)

    elif es_info_empresa:
        # (L√≥gica de informaci√≥n de la empresa)
        contexto = f"""Informaci√≥n de la empresa:
Nombre: {info.get('nombre', 'Stone Creek Coffee')}
Misi√≥n: {info.get('mision', 'Ofrecer la esencia aut√©ntica del caf√© y cacao peruano.')}
Visi√≥n: {info.get('vision', 'Ser la marca latinoamericana l√≠der en experiencias de cata consciente.')}
Contacto: Tel√©fono {info.get('telefono', '')} / Email {info.get('email', '')}
Direcci√≥n: {info.get('direccion', '')}
Descripci√≥n: {empresa_descripcion}

Historial de la conversaci√≥n:
{historial_texto}"""

        respuesta = generar_respuesta_con_gemini(contexto, mensaje, nombre_chatbot)
    
    else:
        # (Respuesta gen√©rica)
        contexto = f"""Eres {nombre_chatbot}, asistente de Stone Creek Coffee. Tu misi√≥n es ayudar a los clientes a descubrir su bebida o postre ideal. Eres amable y entusiasta.

Empresa: {empresa_descripcion}

Pregunta del cliente: {mensaje}

Historial de la conversaci√≥n:
{historial_texto}"""

        respuesta = generar_respuesta_con_gemini(contexto, mensaje, nombre_chatbot)

    # Guardar respuesta en historial
    CONVERSATION_HISTORY[user_id].append({"role": "assistant", "content": respuesta})
    return respuesta